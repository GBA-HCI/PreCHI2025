{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f2cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b885dd6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533e0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/program.json\", \"r\") as f:\n",
    "    program = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d171aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A1 - GenAI-Enhanced Communication', 'B1 - Healthcare and Human Wellbeing', 'A2 - Interactive Systems and Data Visualization', 'B2 - New Media and Research Inspirations', 'A3 - Technology-Enhanced Learning and Heritage', 'B3 - Interaction in VR/AR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18132c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e56b158d-1e9b-462a-a171-710ed8dbc85b",
       "rows": [
        [
         "0",
         "A1 - GenAI-Enhanced Communication",
         "[CHI25] Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech"
        ],
        [
         "1",
         "A1 - GenAI-Enhanced Communication",
         "[CHI25] Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews"
        ],
        [
         "2",
         "A1 - GenAI-Enhanced Communication",
         "[CHI25] \"Ronaldo's a poser!\": How the Use of Generative AI Shapes Debates in Online Forums"
        ],
        [
         "3",
         "A1 - GenAI-Enhanced Communication",
         "[CHI25] JournalAIde: Empowering Older Adults in Digital Journal Writing"
        ],
        [
         "4",
         "A1 - GenAI-Enhanced Communication",
         "[CHI25] HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>[CHI25] Rambler in the Wild: A Diary Study of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>[CHI25] Scaffolded Turns and Logical Conversat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>[CHI25] \"Ronaldo's a poser!\": How the Use of G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>[CHI25] JournalAIde: Empowering Older Adults i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>[CHI25] HarmonyCut: Supporting Creative Chines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             session  \\\n",
       "0  A1 - GenAI-Enhanced Communication   \n",
       "1  A1 - GenAI-Enhanced Communication   \n",
       "2  A1 - GenAI-Enhanced Communication   \n",
       "3  A1 - GenAI-Enhanced Communication   \n",
       "4  A1 - GenAI-Enhanced Communication   \n",
       "\n",
       "                                               title  \n",
       "0  [CHI25] Rambler in the Wild: A Diary Study of ...  \n",
       "1  [CHI25] Scaffolded Turns and Logical Conversat...  \n",
       "2  [CHI25] \"Ronaldo's a poser!\": How the Use of G...  \n",
       "3  [CHI25] JournalAIde: Empowering Older Adults i...  \n",
       "4  [CHI25] HarmonyCut: Supporting Creative Chines...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_df = pd.DataFrame([\n",
    "    {\"session\": key, \"title\": value}\n",
    "    for key, values in program.items()\n",
    "    for value in values\n",
    "])\n",
    "program_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e7118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "conference",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "750120c1-5230-4a4f-8c2b-bc0337e34322",
       "rows": [
        [
         "0",
         "A1 - GenAI-Enhanced Communication",
         "Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech",
         "CHI25"
        ],
        [
         "1",
         "A1 - GenAI-Enhanced Communication",
         "Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews",
         "CHI25"
        ],
        [
         "2",
         "A1 - GenAI-Enhanced Communication",
         "\"Ronaldo's a poser!\": How the Use of Generative AI Shapes Debates in Online Forums",
         "CHI25"
        ],
        [
         "3",
         "A1 - GenAI-Enhanced Communication",
         "JournalAIde: Empowering Older Adults in Digital Journal Writing",
         "CHI25"
        ],
        [
         "4",
         "A1 - GenAI-Enhanced Communication",
         "HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony",
         "CHI25"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>title</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>Rambler in the Wild: A Diary Study of LLM-Assi...</td>\n",
       "      <td>CHI25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>Scaffolded Turns and Logical Conversations: De...</td>\n",
       "      <td>CHI25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>\"Ronaldo's a poser!\": How the Use of Generativ...</td>\n",
       "      <td>CHI25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>JournalAIde: Empowering Older Adults in Digita...</td>\n",
       "      <td>CHI25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 - GenAI-Enhanced Communication</td>\n",
       "      <td>HarmonyCut: Supporting Creative Chinese Paper-...</td>\n",
       "      <td>CHI25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             session  \\\n",
       "0  A1 - GenAI-Enhanced Communication   \n",
       "1  A1 - GenAI-Enhanced Communication   \n",
       "2  A1 - GenAI-Enhanced Communication   \n",
       "3  A1 - GenAI-Enhanced Communication   \n",
       "4  A1 - GenAI-Enhanced Communication   \n",
       "\n",
       "                                               title conference  \n",
       "0  Rambler in the Wild: A Diary Study of LLM-Assi...      CHI25  \n",
       "1  Scaffolded Turns and Logical Conversations: De...      CHI25  \n",
       "2  \"Ronaldo's a poser!\": How the Use of Generativ...      CHI25  \n",
       "3  JournalAIde: Empowering Older Adults in Digita...      CHI25  \n",
       "4  HarmonyCut: Supporting Creative Chinese Paper-...      CHI25  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_df[\"conference\"] = program_df[\"title\"].str.split(\"] \").map(lambda x: x[0][1:])\n",
    "program_df[\"title\"] = program_df[\"title\"].str.split(\"] \").map(lambda x: x[1])\n",
    "\n",
    "program_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5890af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_df = pd.read_excel(\"data/Talk and Poster.xlsx\", sheet_name=\"Talk\")\n",
    "registrant_df = pd.read_excel(\"data/PreCHI Participants.xlsx\", sheet_name=\"Registrant\")\n",
    "sv_df = pd.read_excel(\"data/PreCHI Participants.xlsx\", sheet_name=\"Student Volunteer\")\n",
    "oc_df = pd.read_excel(\"data/PreCHI Participants.xlsx\", sheet_name=\"Organizing Committee\")\n",
    "guest_talk_df = pd.read_excel(\"data/Talk and Poster.xlsx\", sheet_name=\"Guest Talk\")\n",
    "guest_df = pd.read_excel(\"data/PreCHI Participants.xlsx\", sheet_name=\"Guest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2824e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: ÂêàÂπ∂ÊâÄÊúâ Talk Êï∞ÊçÆ\n",
    "all_talks = pd.concat([talk_df, guest_talk_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63ddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Email",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Affiliation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Abstract",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "99732836-e849-446f-ba8b-a73cae336500",
       "rows": [
        [
         "0",
         "1.0",
         "Zhida Sun",
         "zhida.sun@connect.ust.hk",
         "Shenzhen University",
         "[CHI25] Creative Blends of Visual Concepts",
         "Visual blends combine elements from two distinct visual concepts into a single, integrated image, with the goal of conveying ideas through imaginative and often thought-provoking visuals. Communicating abstract concepts through visual blends poses a series of conceptual and technical challenges. To address these challenges, we introduce Creative Blends, an AI-assisted design system that leverages metaphors to visually symbolize abstract concepts by blending disparate objects. Our method harnesses commonsense knowledge bases and large language models to align designers' conceptual intent with expressive concrete objects. Additionally, we employ generative text-to-image techniques to blend visual elements through their overlapping attributes. A user study (N=24) demonstrated that our approach reduces participants' cognitive load, fosters creativity, and enhances the metaphorical richness of visual blend ideation. We explore the potential of our method to expand visual blends to include multiple object blending and discuss the insights gained from designing with generative AI."
        ],
        [
         "1",
         "2.0",
         "Runze Cai",
         "runze.cai@u.nus.edu",
         "National University of Singapore",
         "[CHI25] AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses",
         "Unlike the free exploration of childhood, the demands of daily life reduce our motivation to explore our surroundings, leading to missed opportunities for informal learning. Traditional tools for knowledge acquisition are reactive, relying on user initiative and limiting their ability to uncover hidden interests. Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping). AiGet analyzes real-time user gaze patterns, environmental context, and user profiles, leveraging large language models to deliver personalized, context-aware knowledge with low disruption to primary tasks. In-lab evaluations and real-world testing, including continued use over multiple days, demonstrate AiGet‚Äôs effectiveness in uncovering overlooked yet surprising interests, enhancing primary task enjoyment, reviving curiosity, and deepening connections with the environment. We further propose design guidelines for AI-assisted informal learning, focused on transforming everyday moments into enriching learning experiences."
        ],
        [
         "2",
         "3.0",
         "Xi Zheng",
         "zheng.xi@my.cityu.edu.hk",
         "City University of Hong Kong",
         "[CHI25] Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots",
         "Personalized support is essential to fulfill individuals‚Äô emotional needs and sustain their mental well-being. Large language models (LLMs), with great customization flexibility, hold promises to enable individuals to create their own emotional support agents. In this work, we developed ChatLab, where users could construct LLM-powered chatbots with additional interaction features including voices and avatars. Using a Research through Design approach, we conducted a week-long field study followed by interviews and design activities (N = 22), which uncovered how participants created diverse chatbot personas for emotional reliance, confronting stressors, connecting to intellectual discourse, reflecting mirrored selves, etc. We found that participants actively enriched the personas they constructed, shaping the dynamics between themselves and the chatbot to foster open and honest conversations. They also suggested other customizable features, such as integrating online activities and adjustable memory settings. Based on these findings, we discuss opportunities for enhancing personalized emotional support through emerging AI technologies."
        ],
        [
         "3",
         "4.0",
         "Hanfang Lyu ¬¶ ÂêïÊ∂µÊîæ",
         "hanfang.lyu@connect.ust.hk",
         "The Hong Kong University of Science and Technology",
         "[CHI25] Signaling Human Intentions to Service Robots: Understanding the Use of Social Cues during In-Person Conversations",
         "As service robots become commonplace, it is essential for them to effectively interpret human signals, such as verbal, gesture, and eye gaze, in social contexts, where people need to focus on their primary tasks to minimize interruptions and distractions. Towards such a socially acceptable Human-Robot Interaction, we conducted a study (N=24) in an AR-simulated context of a coffee chat. Participants elicited social cues for signaling intentions to an anthropomorphic, zoomorphic, grounded technical, or aerial technical robot waiter when they were speakers or listeners. Our findings reveal the common patterns of social cues over intentions, the effects of robot morphology on social cue position and conversational role on social cue complexity, and users' rationale in choosing social cues. We offer insights into understanding social cues concerning perceptions of robots, cognitive load, and social context. Additionally, we discuss design considerations on approaching, social cue recognition, and response strategies for future service robots."
        ],
        [
         "4",
         "5.0",
         "Runhua ZHANG ¬¶ Âº†Ê∂¶Ëä±",
         "runhua.zhang@connect.ust.hk",
         "The Hong Kong University of Science and Technology",
         "[CHI 25] Walk in Their Shoes to Navigate Your Own Path: Learning About Procrastination Through A Serious Game",
         "Procrastination, the voluntary delay of tasks despite potential negative consequences, has prompted numerous time and task management interventions in the HCI community. While these interventions have shown promise in addressing specific behaviors, psychological theories suggest that learning about procrastination itself may help individuals develop their own coping strategies and build mental resilience. However, little research has explored how to support this learning process through HCI approaches. We present ProcrastiMate, a text adventure game where players learn about procrastination's causes and experiment with coping strategies by guiding in-game characters in managing relatable scenarios. Our field study with 27 participants revealed that ProcrastiMate facilitated learning and self-reflection while maintaining psychological distance, motivating players to integrate newly acquired knowledge in daily life. This paper contributes empirical insights on leveraging serious games to facilitate learning about procrastination and offers design implications for addressing psychological challenges through HCI approaches."
        ],
        [
         "5",
         "6.0",
         "Xiang (Nathan) Qi",
         "nathanxiang.qi@connect.polyu.hk",
         "The Hong Kong Polytechnic University",
         "[CHI25] Participatory Design in Human-Computer Interaction: Cases, Characteristics, and Lessons",
         "Participatory Design (PD) has become increasingly prevalent inHuman-Computer Interaction (HCI) research. However, there remains a lack of comprehensive understanding of how PD has beenused by HCI scholars. To bridge this gap, we sampled PD applicationcases (ùëÅ = 185) from the SIGCHI conferences over the past decadeand examined these cases through the dimensions of applicationfeatures (e.g., contexts and functions of PD) and PD principles (e.g.,its political commitment and mutual learning principle). Our analysis reveals the various ways PD has been applied in HCI and howits core features have been or have not been manifested in thesecases. Based on these findings, we reflect on the conceptual understanding of PD within the HCI community and discuss potentialmisconceptions. Ultimately, we hope this work can serve as a usefulreference for HCI researchers and beyond who are interested inincorporating PD into their design and research practices."
        ],
        [
         "6",
         "7.0",
         "Fan Zhang",
         "zfan1218@gmail.com",
         "City University Of Hong Kong",
         "[CHI25] \"Becoming My Own Audience\": How Dancers React to Avatars Unlike Themselves in Motion Capture-Supported Live Improvisational Performance",
         "The use of motion capture in live dance performances has created an emerging discipline enabling dancers to play different avatars on the digital stage. Unlike classical workflows, avatars enable performers to act as different characters in customized narratives, but research has yet to address how movement, improvisation, and perception change when dancers act as avatars. We created five avatars representing differing genders, shapes, and body limitations, and invited 15 dancers to improvise with each in practice and performance settings. Results show that dancers used avatars to distance themselves from their own habitual movements, exploring new ways of moving through differing physical constraints. Dancers explored using gender-stereotyped movements like powerful or feminine actions, experimenting with gender identity. However, focusing on avatars can coincide with a lack of continuity in improvisation. This work shows how emerging practices with performance technology enable dancers to improvise with new constraints, stepping outside the classical stage."
        ],
        [
         "7",
         "8.0",
         "Yuhao Sun",
         "yuhao.sun@ed.ac.uk",
         "University of Edinburgh",
         "[CHI25] Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction",
         "Precision Medicine (PM) transforms the traditional \"one-drug-fits-all\" paradigm by customising treatments based on individual characteristics, and is an emerging topic for HCI research on digital health. A key element of PM, the Polygenic Risk Score (PRS), uses genetic data to predict an individual's disease risk. Despite its potential, PRS faces barriers to adoption, such as data inclusivity, psychological impact, and public trust. We conducted a mixed-methods study to explore how people perceive PRS, formed of surveys (n=254) and interviews (n=11) with UK-based participants. The interviews were supplemented by interactive storyboards with the ContraVision technique to provoke deeper reflection and discussion. We identified ten key barriers and five themes to PRS adoption and proposed design implications for a responsible PRS framework. To address the complexities of PRS and enhance broader PM practices, we introduce the term Human-Precision Medicine Interaction (HPMI), which integrates, adapts, and extends HCI approaches to better meet these challenges."
        ],
        [
         "8",
         "9.0",
         "Yuanhao ZHANG",
         "yzhangiy@connect.ust.hk",
         "HKUST",
         "[CHI25] CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos",
         "Danmaku, a system of scene-aligned, time-synced, floating comments, can augment video content to create `collective knowledge'. However, its chaotic nature often hinders viewers from effectively assimilating the collective knowledge, especially in knowledge-intensive science videos. With a formative study, we examined viewers' practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge -- a tool incorporating a video abstract, knowledge graphs, and supplementary danmaku features to support viewers' assimilation of collective knowledge in science videos. A within-subject study (N=24) showed that CoKnowledge significantly enhanced participants‚Äô comprehension and recall of collective knowledge compared to a baseline with unprocessed live comments. Based on our analysis of user interaction patterns and feedback on design features, we presented design considerations for developing similar support tools."
        ],
        [
         "9",
         "10.0",
         "Yanna Lin",
         "cseyanna@ust.hk",
         "HKUST",
         "[CHI25] InterLink: Linking Text with Code and Outputs in Computational Notebooks",
         "Computational notebooks, widely used for ad-hoc analysis and often shared with others, can be difficult to understand because the standard linear layout is not optimized for reading. In particular, related text, code, and outputs may be spread across the UI making it difficult to draw connections. In response, we introduce InterLink, a plugin designed to present the relationships between text, code, and outputs, thereby making notebooks easier to understand. In a formative study, we identify pain points and derive design requirements for identifying and navigating relationships among various pieces of information within notebooks. Based on these requirements, InterLink features a new layout that separates text from code and outputs into two columns. It uses visual links to signal relationships between text and associated code and outputs and offers interactions for navigating related pieces of information. In a user study with 12 participants, those using InterLink were 13.6% more accurate at finding and integrating information from complex analyses in computational notebooks. These results show the potential of notebook layouts that make them easier to understand."
        ],
        [
         "10",
         "11.0",
         "LIU Dingdong",
         "dliuak@connect.ust.hk",
         "HKUST",
         "[CHI25] Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews",
         "Hospital admission interviews are critical for patient care but strain nurses' capacity due to time constraints and staffing shortages.While LLM-powered conversational agents (CAs) offer automation potential, their rigid sequencing and lack of humanized communication skills risk misunderstandings and incomplete data capture.Through participatory design with clinicians and volunteers, we identified essential communication strategies and developed a novel CA that implements these strategies through: (1) dynamic topic management using graph-based conversation flows, and (2) context-aware scaffolding with few-shot prompt tuning.Technical evaluation on an admission interview dataset showed our system achieving performance comparable to or surpassing human-written ground truth, while outperforming prompt-engineered baselines.A between-subject study (N=44) demonstrated significantly improved user experience and data collection accuracy compared to existing solutions.We contribute a framework for humanizing medical CAs by translating clinician expertise into algorithmic strategies, alongside empirical insights for balancing efficiency and empathy in healthcare interactions, and considerations for generalizability."
        ],
        [
         "11",
         "12.0",
         "Liangwei Wang",
         "lwang344@connect.hkust-gz.edu.cn",
         "The Hong Kong University of Science and Technology (Guangzhou)",
         "VIzTA: Enhancing Comprehension of Distributional Visualization with Visual-Lexical Fused Conversational Interface",
         "Comprehending visualizations requires readers to interpret visual encoding and the underlying meanings actively. This poses challenges for visualization novices, particularly when interpreting distributional visualizations that depict statistical uncertainty. Advancements in LLM-based conversational interfaces show promise in promoting visualization comprehension. However, they fail to provide contextual explanations at fine-grained granularity, and chart readers are still required to mentally bridge visual information and textual explanations during conversations.Our formative study highlights the expectations for both lexical and visual feedback, as well as the importance of explicitly linking these two modalities throughout the conversation. The findings motivate the design of VIzTA, a visualization teaching assistant that leverages the fusion of visual and lexical feedback to help readers better comprehend visualization. VIzTA features a semantic-aware conversational agent capable of explaining contextual information within visualizations and employs a visual-lexical fusion design to facilitate chart-centered conversation. A between-subject study with 24 participants demonstrates the effectiveness of VIzTA in supporting the understanding and reasoning tasks of distributional visualization across multiple scenarios."
        ],
        [
         "12",
         "13.0",
         "Yue Zhang",
         "yuezh@ust.hk",
         "HKUST",
         "[CHI25] InsightBridge: Enhancing Empathizing with Users through Real-Time Information Synthesis and Visual Communication",
         "User-centered design necessitates researchers deeply understanding target users throughout the design process. However, during early-stage user interviews, researchers may misinterpret users due to time constraints, incorrect assumptions, and communication barriers. To address this challenge, we introduce InsightBridge, a tool that supports real-time, AI-assisted information synthesis and visual-based verification. InsightBridge automatically organizes relevant information from ongoing interview conversations into an empathy map. It further allows researchers to specify elements to generate visual abstracts depicting the selected information, and then review these visuals with users to refine the visuals as needed. We evaluated the effectiveness of InsightBridge through a within-subject study (N=32) from both the researchers‚Äô and users‚Äô perspectives. Our findings indicate that InsightBridge can assist researchers in note-taking and organization, as well as in-time visual checking, thereby enhancing mutual understanding with users. Additionally, users‚Äô discussions of visuals prompt them to recall overlooked details and scenarios, leading to more insightful ideas."
        ],
        [
         "13",
         "14.0",
         "Zijun Mai",
         "zijunmai@stu2023.jnu.edu.cn",
         "Jinan University",
         "[CHI25] Modeling Locomotion with Body Angular Movements in Virtual Reality",
         "This study proposes a time prediction model for locomotion along a polyline path with body angular movements in Virtual Reality (VR). We divide such locomotion into two components: navigating in multiple line-segment paths and turning at line-segment intersections. In the first component, locomotion in each line-segment path consists of acceleration, maximum velocity, and deceleration phases. We formulate equations to estimate the locomotion time for each phase and accumulated them to model the total time. In the second component, a linear relationship was revealed between task time and turning angles. We established an integrated model based on the equations of the two components and verified the effectiveness of the model with three experiments. The results indicate that our model outperformed two baseline models with a greater ŒæRÀÜ2Œæ and a smaller gap between the predicted and actual time. Our study benefits VR locomotion design with body angular movements."
        ],
        [
         "14",
         "15.0",
         "Haoxiang Fan",
         "fanhx6@mail2.sysu.edu.cn",
         "Sun Yat-sen University",
         "[CHI25] LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools Authors",
         "Teaching literature under interdisciplinary contexts (e.g., science, art) that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with the literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker‚Äôs usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs."
        ],
        [
         "15",
         "16.0",
         "Tianze XIE",
         "tiaraaaxie@gmail.com",
         "SUSTech",
         "[CHI25] VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR",
         "Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR."
        ],
        [
         "16",
         "17.0",
         "Han SHI",
         "hshi22@m.fudan.edu.cn",
         "SUSTech/Fudan University",
         "[CHI25] ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting",
         "The advancement of Virtual Reality (VR) has expanded 2D userinterfaces into 3D space. This change has introduced richer interaction modalities but also brought challenges, especially the lackof haptic feedback in mid-air interactions. Previous research hasexplored various methods to provide feedback for interface interactions, but most approaches require specialized haptic devices.We introduce haptic retargeting to enable users to control multiple virtual screens in VR using a simple flat pad, which servesas a single physical proxy to support seamless interaction acrossmultiple virtual screens. We conducted user studies to explore theappropriate virtual screen size and positioning under our retargeting method and then compared various drag-and-drop methods for cross-screen interaction. Finally, we compared our method withcontroller-based interaction in application scenarios."
        ],
        [
         "17",
         "18.0",
         "Huanchen Wang",
         "wanghc2022@mail.sustech.edu.cn",
         "SUSTech & CityUHK",
         "[CHI25] HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony",
         "Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users' and models' lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation."
        ],
        [
         "18",
         "19.0",
         "yao shi",
         "yshi236@connect.hkust-gz.edu.cn",
         "The Hong Kong University of Science and Technology (Guangzhou)",
         "[CHI25] Augmenting Realistic Charts with Virtual Overlays",
         "In this paper, we introduce the concept of realistic charts, referring to charts in the real world that cannot be digitally altered, such as those printed in newspapers or used in presentations. By enabling interaction with and graphical enhancement of these realistic charts as if they were digital, we transform realistic charts into ‚Äúdigital charts‚Äù by adding virtual graphical overlays. To achieve this, we identify 33 overlay strategies (e.g., highlights and trendlines) for five widely-used chart types (e.g., line charts) through systematic exploration and a formative study. To simplify overlay creation, we introduce a new grammar named Vega-Overlay. Leveraging this design space and grammar, we develop a system called HARVis, which allows users to generate virtual overlays through augmented reality devices using speech and optional gestures. A user study involving 33 participants from diverse fields, across 17 tasks, demonstrates the effectiveness and usability of HARVis."
        ],
        [
         "19",
         "20.0",
         "Sze Yiu",
         "szeyiuchau@cuhk.edu.hk",
         "The Chinese University of Hong Kong",
         "[CHI25] SeQR: A User-Friendly and Secure-by-Design Configurator for Enterprise Wi-Fi",
         "A classic problem in enterprise Wi-Fi is client-side misconfiguration, which enables credential theft via Èà•Ê∑ìvil TwinÈà•?(ET) attacks. To mitigate this, we design, develop, and evaluate a new configurator, SeQR, which allows users to effortlessly and securely set up an enterprise Wi-Fi connection. Utilizing existing authenticated channels, SeQR fully automates the client-side enterprise Wi-Fi configuration process with a simple scan, leaving no room for misconfigurations. Specifically, SeQR thwarts ET by making it impossible for users to opt-out from the security-critical certificate validation. We evaluate the efficacy of SeQR on two fronts. First, we implement a prototype of SeQR in Android, and test its functionality and runtime performance. Next, we compare the usability of SeQR against two existing Wi-Fi configuration interfaces of Android in an in-person user study (n=41) with real devices. Our evaluation shows that SeQR achieves noticeable usability improvements over existing designs, and prevents users from misconfiguring."
        ],
        [
         "20",
         "21.0",
         "Yuhan Zeng (Tsang)",
         "yhzeng3-c@my.cityu.edu.hk",
         "City University of Hong Kong",
         "[CHI25] \"Ronaldo's a poser!\": How the Use of Generative AI Shapes Debates in Online Forums",
         "Online debates can enhance critical thinking but may escalate into hostile attacks. As humans are increasingly reliant on Generative AI (GenAI) in writing tasks, we need to understand how people utilize GenAI in online debates. To examine the patterns of writing behavior while making arguments with GenAI, we created an online forum for soccer fans to engage in turn-based and free debates in a post format with the assistance of ChatGPT, arguing on the topic of \"Messi vs Ronaldo\". After 13 sessions of two-part study and semi-structured interviews with 39 participants, we conducted content and thematic analyses to integrate insights from interview transcripts, ChatGPT records, and forum posts. We found that participants prompted ChatGPT for aggressive responses, created posts with similar content and logical fallacies, and sacrificed the use of ChatGPT for better human-human communication. This work uncovers how polarized forum members work with GenAI to engage in debates online."
        ],
        [
         "21",
         "22.0",
         "Wei Liu",
         "liuwei.dk@gmail.com",
         "School of Design, Southern University of Science and Technology",
         "[REP] Empathy-Driven Interaction Design ",
         "Empathy is a fundamental principle in Human-Computer Interaction (HCI), shaping the design of intuitive, inclusive, and emotionally resonant experiences. This talk introduces Empathy-Driven Interaction Design (EDID)Èà•ÊîÅ human-centered framework that integrates psychological insights, interaction qualities, and experiential design to improve usability and accessibility. Applications in assistive technology, user-friendly interfaces, and emotion-aware systems will be explored, demonstrating how empathy can be systematically embedded in design processes. Case studies and research will highlight strategies for fostering deeper user engagement and creating meaningful interactions that go beyond functionality to establish genuine user connections."
        ],
        [
         "22",
         "23.0",
         "Jiaan LI",
         "jiaan.li@connect.polyu.hk",
         "Hong Kong Polytechnic University",
         "[CHI25] Designing and Evaluating a Narrative-driven Spatial Visualization for Improving Patient-centered Communication among Older Adults",
         "With the aging population, older adult patients experience difficulties in communicating and understanding medical information within healthcare settings. This late-breaking work focuses on designing and evaluating narrative-driven spatial visualization (N-dSV) through conducting iterative participatory design with clinicians and older adults. The results indicate that compared with the traditional paper-based mode, this innovative information communication mode can significantly improve older adultsÈà•?understanding of medical information and have a higher willingness to use it, thus improving the patient-centered communication experience. Finally, we propose three design implications to provide references for research in the HCI field to optimize patient-centered communication in medical scenarios by using narration-driven spatial visualization as a framework."
        ],
        [
         "23",
         "24.0",
         "Chutian Jiang",
         "cjiang893@connect.hkust-gz.edu.cn",
         "Hong Kong University of Science and Technology (Guangzhou)",
         "[CHI25] Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners",
         "Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools' use in other hands-on skills instruction and cognitive process differences in various courses.\n"
        ],
        [
         "24",
         "25.0",
         "Shixu ZHOU",
         "szhouav@connect.ust.hk",
         "HKUST",
         "[CHI25] JournalAIde: Empowering Older Adults in Digital Journal Writing",
         "Digital journaling offers a means for older adults to express themselves, document their lives, and engage in self-reflection, contributing to the maintenance of cognitive function and social connectivity. Although previous works have investigated the motivations and benefits of digital journaling for older adults, little technical support has been designed to offer assistance. We conducted a formative study with older adults and uncovered their encountered challenges and preferences for technical support. Informed by the findings, we designed a Large Language Model (LLM) empowered tool, JournalAIde, which provides vicarious experience, idea organization, sample text generation, and visual editing cues to enhance older adultsÈà•?confidence, writing ability, and sustained attention during digital journaling. Through a between-subjects study and a field deployment, we demonstrated the JournalAIdeÈà•Ê™ö significant effectiveness compared to a baseline system in empowering older adults in digital journaling. We further investigated older adults' experiences and perceptions of LLM writing assistance."
        ],
        [
         "25",
         "26.0",
         "ÈÉ≠ËΩ∂Êç∑",
         "guoyijie.sh@gmail.com",
         "Tsinghua University",
         "[CHI25] Exploring the Design of LLM-based Agent in Enhancing Self-disclosure Among the Older Adults",
         "Social difficulties have become an increasingly serious issue among older adults. For older adults, regular self-disclosure is essential for maintaining mental health and building close relationships. Leveraging conversational agents to encourage self-disclosure in older adults has shown increasing potential. Understanding how LLM-based agents can influence and stimulate self-disclosure across different topics is crucial for designing future agents tailored to older users. This study introduces Disclosure-Agent, an LLM-based conversational agent, and examines its impact on self-disclosure in older adults through a user study involving 20 participants, 8 topics, and two interactive interfaces equipped with Disclosure-Agent. The findings provide valuable insights into how LLM-based agents can promote self-disclosure in older adults and offer design recommendations for future elderly-oriented conversational agents."
        ],
        [
         "26",
         "27.0",
         "Âº†Â≠êÊôó",
         "2237948243@qq.com",
         "SUSTech",
         "[CHI25] Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate",
         "Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under- explored in HCI. This study addresses this opportunity by investi- gating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from Chat- GPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage‚Äîreducing social anxiety, breaking communication barriers, and providing scaffolding for novices‚Äîalongside risks, such as in- formation overload and cognitive dependency, which could limit learners‚Äô autonomy. We thereby discuss a set of nuanced implica- tions for future HCI exploration."
        ],
        [
         "27",
         "28.0",
         "Ziqi Pan",
         "zpanar@connect.ust.hk",
         "HKUST",
         "[CHI25] ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts",
         "Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects' affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents' planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study's feedback demonstrated ACKnowledge's negotiation and personalization capabilities toward an understandable planning process."
        ],
        [
         "28",
         "29.0",
         "Xuyu Yang",
         "xuyuyang2-c@my.cityu.edu.hk",
         "City University of Hong Kong",
         "[CHI25] Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech",
         "Speech-to-text technologies have been shown to improve text input efficiency and potentially lower the barriers to writing. Recent LLM-assisted dictation tools aim to support writing with speech by bridging the gaps between speaking and traditional writing. This case study reports on the real-world writing experiences of twelve academic or creative writers using one such tool ‚Äì Rambler, to write various articles such as blog posts, diaries, screenplays, notes, or fictional stories, etc. Through a ten-day diary study, we identified the participants‚Äô in-context writing strategies using Rambler, such as how they expanded from an outline or organized their loose thoughts for different writing goals. The interviews uncovered the psychological and productivity affordances of writing with speech, pointing to future directions of designing for this writing modality and the utilization of AI support."
        ],
        [
         "29",
         "30.0",
         "Yingna Wang",
         "ywang885@connect.hkust-gz.edu.cn",
         "The Hong Kong University of Science and Technology (Guangzhou))",
         "[CHI25] Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement",
         "The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR's potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners' challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills."
        ],
        [
         "30",
         "31.0",
         "Xin Tang",
         "xintang0119@gmail.com",
         "Guangzhou Academy of Fine Arts",
         "Computational Methods for Batik Discovery, Preservation and Development",
         "For centuries, Batik has served as a reflection of humanity's relationship with nature, societal dynamics, and daily experiences. Due to its intricate procedures and meticulous techniques, Batik encounters challenges when integrating into the contemporary era. To address this, research teams have designed and developed a series of computational Batik works. These systems merge traditional Batik practices with contemporary digital mediums, offering interactive user experiences. Through these systems, users can produce digital artworks encapsulating the essence of traditional Batik craftsmanship. These computational Batik series serve as a medium for cultural exchange, promoting interactions among Batik traditions from diverse countries and playing a pivotal role in establishing a unified global artistic community. Simultaneously, these systems bridge traditional Batik craftsmanship with modern technology, facilitating the innovative transformation and creative evolution of Batik through digitalization and virtualization."
        ],
        [
         "31",
         "32.0",
         "Zhihao Yao",
         "yaozh_h@outlook.com",
         "Tsinghua University",
         "Research on Digital Creative Tools for Traditional Arts",
         "In the transformation process of re-mediating traditional arts, creative tools play a vital role as the core medium connecting technology and artistic creation. This research focuses on two traditional art forms‚Äîink painting and shadow puppetry‚Äîas research subjects, exploring approaches to constructing creative support tools. Through relevant user studies, the effectiveness of the tool design has been demonstrated."
        ],
        [
         "32",
         "33.0",
         "RAY LC",
         "recfreq@gmail.com",
         "City University of Hong Kong",
         "[CSCW] A Constructed Response: Designing and Choreographing Robot Arm Movements in Collaborative Dance Improvisation",
         "In dance, dancers improvise and choreograph with each other, prototyping movement designs with each other. These interactions extend into collaboration with technology to enhance the creative process. We want to understand how dancers design and improvise movements together in the case of working with a robotic arm, which serves as an instrument in the stage space capable of non-humanoid movements. We engaged and observed dancers in a workshop to co-create movements with robots in one-human-to-one-robot and three-human-to-one-robot settings. We found that dancers produced more fluid movements in one-to-one scenarios, experiencing a stronger sense of connection and presence with the robot as a co-dancer. Conversely, in three-to-one scenarios, the dancers divided their attention between the human dancers and the robot, resulting in increased perceived use of space and more stop-and-go movements, perceiving the robot as part of the stage background. This work highlights how technologies can drive creativity in movement artists as they adapt to new ways of working with instruments, extending prior research on dancing with inanimate objects by exploring how robotic arms influence creative collaboration. We contribute insights into designing systems that support improvisational processes and artistic collaborations with non-humanoid agents."
        ],
        [
         "33",
         "34.0",
         "Maggie Yongqi Guan",
         "maggiegyq2021@gmail.com",
         "University of Macau",
         "[CHI25] Using Affordance to Understand Usability of Web3 Social Media",
         "Web3 social media refers to a new generation of platforms built on decentralized technologies, particularly blockchain. Although academia has investigated the newly emerging Web3 social media, it is not clear how users perceive the usability of such platforms and how these perceptions are influenced by the inherent characteristics of Web3. To address this gap, we utilize affordance theory to explore the unique usability of Web3 social media compared with Web2 social media. We conducted interviews with 32 participants who are experienced with Web3 social media and examined the affordances of Web3 social media from the perspectives of content creation, content consumption, and community interaction. We further discuss the correlation between the usability of Web3 social media and the underlying decentralized technology, and provide design implications for enhancing the usability of this new type of social interaction platform."
        ],
        [
         "34",
         "35.0",
         "Tian Yang",
         "ytian@gxu.edu.cn",
         "Guangxi University",
         "[REP] Designing Highly Accessible XR Interfaces",
         null
        ],
        [
         "35",
         "36.0",
         "‰æØ‰ºäÊ∂µ",
         "yhou073@connect.hkust-gz.edu.cn",
         "The Hong Kong University of Science and Technology (Guangzhou))",
         "[CHI25] GenColor: Generative Color-Concept Association in Visual Design",
         "Existing approaches for color-concept association typically rely on query-based image referencing, and color extraction from image references. However, these approaches are effective only for common concepts, and are vulnerable to unstable image referencing and varying image conditions. Our formative study with designers underscores the need for primary-accent color compositions and context-dependent colors (e.g., 'clear' vs. 'polluted' sky) in design. In response, we introduce a generative approach for mining semantically resonant colors leveraging images generated by text-to-image models. Our insight is that contemporary text-to-image models can resemble visual patterns from large-scale real-world data. The framework comprises three stages: concept instancing produces generative samples using diffusion models, text-guided image segmentation identifies concept-relevant regions within the image, and color association extracts primarily accompanied by accent colors. Quantitative comparisons with expert designs validate our approach's effectiveness, and we demonstrate the applicability through cases in various design scenarios and a gallery."
        ],
        [
         "36",
         "37.0",
         "Yuan Kangyu",
         "kyuanaf@connect.ust.hk",
         "The Hong Kong University of Science and Technology",
         "[CSCW] Exploring the Evolvement of User Engagement in Online Creative Community under the Surge of Generative AI: A Case Study of DeviantArt",
         "The rise of AI-generated content (AIGC) is transforming online creative communities (OCCs) and posing challenges to their regulation. The interacting behaviors, such as sharing artworks with descriptions, commenting on creations, and creators‚Äô subsequent replying are the essential components of user engagement in these communities. Understanding the influence of AIGC on the evolving user engagement could be helpful for community regulation. In this work, we collect 235K posts and their associated 255K comments from DeviantArt, a large creative community allowing uploading AIGC. Through open coding, we identify five categories of practices in describing and commenting on artworks, respectively. A set of deep learning models are applied to classify the posts and comments. We then combine time series regression analysis, causal inference analysis, and logistic regression analysis, to examine the impact of the surge of AIGC on user engagement. Results suggest that AI-generated artworks show a decreasing emphasis on the content of creations but an increasing trend toward commercial and promotion purposes. AI-generated artworks emphasize less on IP issues than human-created ones, while the awareness of IP issues drops for human-created artworks with the growth of AIGC as well. Although comments with high sentiment valence, for peer bonding or for requesting usage positively predict the reply behavior for human-created artworks, community members are less likely to maintain these interactions as AIGC rises. Finally, we discuss insights and design implications for OCCs."
        ],
        [
         "37",
         "1.0",
         "ÈÉ≠ËØóËæâ",
         "guoshihui@xmu.edu.cn",
         "School of Informatics, Xiamen University",
         "Human Motion Capture for Everyone, Anywhere and Allday",
         null
        ],
        [
         "38",
         "2.0",
         "Á±≥Êµ∑Èπè",
         "mhp@tsinghua.edu.cn",
         "Academy of Arts & Design, Tsinghua University",
         "Culture Inheritance and Design Innovation: Research Practice at MILAB",
         null
        ],
        [
         "39",
         "3.0",
         "Â≠ôÈì≠‰ºö",
         "smh@jlu.edu.cn",
         "School of Computer Science and Technology, Jilin University",
         "GazePuffer : Hands-Free Input Method Leveraging Puff Cheeks for VR",
         null
        ],
        [
         "40",
         "4.0",
         "È©¨Êò±Ê¨£",
         "mayx@sustech.edu.cn",
         "Dept. of Computer Science and Engineering, SUSTech",
         "Making Invisible Dynamics Visible: Case Studies in Visualizing Computational and Behavioral Processes",
         null
        ],
        [
         "41",
         "5.0",
         "‰ªòÂøóÂãá",
         "fuzhiyong@tsinghua.edu.cn",
         "Academy of Arts & Design, Tsinghua University",
         "Design Futures in HCI: Design Thinking for Digital Transformation ",
         null
        ],
        [
         "42",
         null,
         "Wei Liu",
         "liuwei.dk@gmail.com",
         "School of Design, Southern University of Science and Technology",
         "Empathy-Driven Interaction Design ",
         "Empathy is a fundamental principle in Human-Computer Interaction (HCI), shaping the design of intuitive, inclusive, and emotionally resonant experiences. This talk introduces Empathy-Driven Interaction Design (EDID)Èà•ÊîÅ human-centered framework that integrates psychological insights, interaction qualities, and experiential design to improve usability and accessibility. Applications in assistive technology, user-friendly interfaces, and emotion-aware systems will be explored, demonstrating how empathy can be systematically embedded in design processes. Case studies and research will highlight strategies for fostering deeper user engagement and creating meaningful interactions that go beyond functionality to establish genuine user connections."
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 43
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Zhida Sun</td>\n",
       "      <td>zhida.sun@connect.ust.hk</td>\n",
       "      <td>Shenzhen University</td>\n",
       "      <td>[CHI25] Creative Blends of Visual Concepts</td>\n",
       "      <td>Visual blends combine elements from two distin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Runze Cai</td>\n",
       "      <td>runze.cai@u.nus.edu</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>[CHI25] AiGet: Transforming Everyday Moments i...</td>\n",
       "      <td>Unlike the free exploration of childhood, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Xi Zheng</td>\n",
       "      <td>zheng.xi@my.cityu.edu.hk</td>\n",
       "      <td>City University of Hong Kong</td>\n",
       "      <td>[CHI25] Customizing Emotional Support: How Do ...</td>\n",
       "      <td>Personalized support is essential to fulfill i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Hanfang Lyu ¬¶ ÂêïÊ∂µÊîæ</td>\n",
       "      <td>hanfang.lyu@connect.ust.hk</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CHI25] Signaling Human Intentions to Service ...</td>\n",
       "      <td>As service robots become commonplace, it is es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Runhua ZHANG ¬¶ Âº†Ê∂¶Ëä±</td>\n",
       "      <td>runhua.zhang@connect.ust.hk</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CHI 25] Walk in Their Shoes to Navigate Your ...</td>\n",
       "      <td>Procrastination, the voluntary delay of tasks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Xiang (Nathan) Qi</td>\n",
       "      <td>nathanxiang.qi@connect.polyu.hk</td>\n",
       "      <td>The Hong Kong Polytechnic University</td>\n",
       "      <td>[CHI25] Participatory Design in Human-Computer...</td>\n",
       "      <td>Participatory Design (PD) has become increasin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Fan Zhang</td>\n",
       "      <td>zfan1218@gmail.com</td>\n",
       "      <td>City University Of Hong Kong</td>\n",
       "      <td>[CHI25] \"Becoming My Own Audience\": How Dancer...</td>\n",
       "      <td>The use of motion capture in live dance perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Yuhao Sun</td>\n",
       "      <td>yuhao.sun@ed.ac.uk</td>\n",
       "      <td>University of Edinburgh</td>\n",
       "      <td>[CHI25] Human-Precision Medicine Interaction: ...</td>\n",
       "      <td>Precision Medicine (PM) transforms the traditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Yuanhao ZHANG</td>\n",
       "      <td>yzhangiy@connect.ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] CoKnowledge: Supporting Assimilation o...</td>\n",
       "      <td>Danmaku, a system of scene-aligned, time-synce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Yanna Lin</td>\n",
       "      <td>cseyanna@ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] InterLink: Linking Text with Code and ...</td>\n",
       "      <td>Computational notebooks, widely used for ad-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>LIU Dingdong</td>\n",
       "      <td>dliuak@connect.ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] Scaffolded Turns and Logical Conversat...</td>\n",
       "      <td>Hospital admission interviews are critical for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Liangwei Wang</td>\n",
       "      <td>lwang344@connect.hkust-gz.edu.cn</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>VIzTA: Enhancing Comprehension of Distribution...</td>\n",
       "      <td>Comprehending visualizations requires readers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Yue Zhang</td>\n",
       "      <td>yuezh@ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] InsightBridge: Enhancing Empathizing w...</td>\n",
       "      <td>User-centered design necessitates researchers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Zijun Mai</td>\n",
       "      <td>zijunmai@stu2023.jnu.edu.cn</td>\n",
       "      <td>Jinan University</td>\n",
       "      <td>[CHI25] Modeling Locomotion with Body Angular ...</td>\n",
       "      <td>This study proposes a time prediction model fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Haoxiang Fan</td>\n",
       "      <td>fanhx6@mail2.sysu.edu.cn</td>\n",
       "      <td>Sun Yat-sen University</td>\n",
       "      <td>[CHI25] LitLinker: Supporting the Ideation of ...</td>\n",
       "      <td>Teaching literature under interdisciplinary co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Tianze XIE</td>\n",
       "      <td>tiaraaaxie@gmail.com</td>\n",
       "      <td>SUSTech</td>\n",
       "      <td>[CHI25] VRCaptions: Design Captions for DHH Us...</td>\n",
       "      <td>Accessing auditory information remains challen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Han SHI</td>\n",
       "      <td>hshi22@m.fudan.edu.cn</td>\n",
       "      <td>SUSTech/Fudan University</td>\n",
       "      <td>[CHI25] ReachPad: Interacting with Multiple Vi...</td>\n",
       "      <td>The advancement of Virtual Reality (VR) has ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Huanchen Wang</td>\n",
       "      <td>wanghc2022@mail.sustech.edu.cn</td>\n",
       "      <td>SUSTech &amp; CityUHK</td>\n",
       "      <td>[CHI25] HarmonyCut: Supporting Creative Chines...</td>\n",
       "      <td>Chinese paper-cutting, an Intangible Cultural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>yao shi</td>\n",
       "      <td>yshi236@connect.hkust-gz.edu.cn</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CHI25] Augmenting Realistic Charts with Virtu...</td>\n",
       "      <td>In this paper, we introduce the concept of rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Sze Yiu</td>\n",
       "      <td>szeyiuchau@cuhk.edu.hk</td>\n",
       "      <td>The Chinese University of Hong Kong</td>\n",
       "      <td>[CHI25] SeQR: A User-Friendly and Secure-by-De...</td>\n",
       "      <td>A classic problem in enterprise Wi-Fi is clien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Yuhan Zeng (Tsang)</td>\n",
       "      <td>yhzeng3-c@my.cityu.edu.hk</td>\n",
       "      <td>City University of Hong Kong</td>\n",
       "      <td>[CHI25] \"Ronaldo's a poser!\": How the Use of G...</td>\n",
       "      <td>Online debates can enhance critical thinking b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Wei Liu</td>\n",
       "      <td>liuwei.dk@gmail.com</td>\n",
       "      <td>School of Design, Southern University of Scien...</td>\n",
       "      <td>[REP] Empathy-Driven Interaction Design</td>\n",
       "      <td>Empathy is a fundamental principle in Human-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Jiaan LI</td>\n",
       "      <td>jiaan.li@connect.polyu.hk</td>\n",
       "      <td>Hong Kong Polytechnic University</td>\n",
       "      <td>[CHI25] Designing and Evaluating a Narrative-d...</td>\n",
       "      <td>With the aging population, older adult patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Chutian Jiang</td>\n",
       "      <td>cjiang893@connect.hkust-gz.edu.cn</td>\n",
       "      <td>Hong Kong University of Science and Technology...</td>\n",
       "      <td>[CHI25] Designing LLM-Powered Multimodal Instr...</td>\n",
       "      <td>Although remote learning is widely used for de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Shixu ZHOU</td>\n",
       "      <td>szhouav@connect.ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] JournalAIde: Empowering Older Adults i...</td>\n",
       "      <td>Digital journaling offers a means for older ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>ÈÉ≠ËΩ∂Êç∑</td>\n",
       "      <td>guoyijie.sh@gmail.com</td>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>[CHI25] Exploring the Design of LLM-based Agen...</td>\n",
       "      <td>Social difficulties have become an increasingl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Âº†Â≠êÊôó</td>\n",
       "      <td>2237948243@qq.com</td>\n",
       "      <td>SUSTech</td>\n",
       "      <td>[CHI25] Breaking Barriers or Building Dependen...</td>\n",
       "      <td>Breaking Barriers or Building Dependency? Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Ziqi Pan</td>\n",
       "      <td>zpanar@connect.ust.hk</td>\n",
       "      <td>HKUST</td>\n",
       "      <td>[CHI25] ACKnowledge: A Computational Framework...</td>\n",
       "      <td>Intelligent agents coexisting with humans ofte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Xuyu Yang</td>\n",
       "      <td>xuyuyang2-c@my.cityu.edu.hk</td>\n",
       "      <td>City University of Hong Kong</td>\n",
       "      <td>[CHI25] Rambler in the Wild: A Diary Study of ...</td>\n",
       "      <td>Speech-to-text technologies have been shown to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Yingna Wang</td>\n",
       "      <td>ywang885@connect.hkust-gz.edu.cn</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CHI25] Facilitating Daily Practice in Intangi...</td>\n",
       "      <td>The essence of intangible cultural heritage (I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Xin Tang</td>\n",
       "      <td>xintang0119@gmail.com</td>\n",
       "      <td>Guangzhou Academy of Fine Arts</td>\n",
       "      <td>Computational Methods for Batik Discovery, Pre...</td>\n",
       "      <td>For centuries, Batik has served as a reflectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Zhihao Yao</td>\n",
       "      <td>yaozh_h@outlook.com</td>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>Research on Digital Creative Tools for Traditi...</td>\n",
       "      <td>In the transformation process of re-mediating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>RAY LC</td>\n",
       "      <td>recfreq@gmail.com</td>\n",
       "      <td>City University of Hong Kong</td>\n",
       "      <td>[CSCW] A Constructed Response: Designing and C...</td>\n",
       "      <td>In dance, dancers improvise and choreograph wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Maggie Yongqi Guan</td>\n",
       "      <td>maggiegyq2021@gmail.com</td>\n",
       "      <td>University of Macau</td>\n",
       "      <td>[CHI25] Using Affordance to Understand Usabili...</td>\n",
       "      <td>Web3 social media refers to a new generation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Tian Yang</td>\n",
       "      <td>ytian@gxu.edu.cn</td>\n",
       "      <td>Guangxi University</td>\n",
       "      <td>[REP] Designing Highly Accessible XR Interfaces</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>‰æØ‰ºäÊ∂µ</td>\n",
       "      <td>yhou073@connect.hkust-gz.edu.cn</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CHI25] GenColor: Generative Color-Concept Ass...</td>\n",
       "      <td>Existing approaches for color-concept associat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Yuan Kangyu</td>\n",
       "      <td>kyuanaf@connect.ust.hk</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>[CSCW] Exploring the Evolvement of User Engage...</td>\n",
       "      <td>The rise of AI-generated content (AIGC) is tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ÈÉ≠ËØóËæâ</td>\n",
       "      <td>guoshihui@xmu.edu.cn</td>\n",
       "      <td>School of Informatics, Xiamen University</td>\n",
       "      <td>Human Motion Capture for Everyone, Anywhere an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Á±≥Êµ∑Èπè</td>\n",
       "      <td>mhp@tsinghua.edu.cn</td>\n",
       "      <td>Academy of Arts &amp; Design, Tsinghua University</td>\n",
       "      <td>Culture Inheritance and Design Innovation: Res...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Â≠ôÈì≠‰ºö</td>\n",
       "      <td>smh@jlu.edu.cn</td>\n",
       "      <td>School of Computer Science and Technology, Jil...</td>\n",
       "      <td>GazePuffer : Hands-Free Input Method Leveragin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.0</td>\n",
       "      <td>È©¨Êò±Ê¨£</td>\n",
       "      <td>mayx@sustech.edu.cn</td>\n",
       "      <td>Dept. of Computer Science and Engineering, SUS...</td>\n",
       "      <td>Making Invisible Dynamics Visible: Case Studie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>‰ªòÂøóÂãá</td>\n",
       "      <td>fuzhiyong@tsinghua.edu.cn</td>\n",
       "      <td>Academy of Arts &amp; Design, Tsinghua University</td>\n",
       "      <td>Design Futures in HCI: Design Thinking for Dig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wei Liu</td>\n",
       "      <td>liuwei.dk@gmail.com</td>\n",
       "      <td>School of Design, Southern University of Scien...</td>\n",
       "      <td>Empathy-Driven Interaction Design</td>\n",
       "      <td>Empathy is a fundamental principle in Human-Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                Name                              Email  \\\n",
       "0    1.0           Zhida Sun           zhida.sun@connect.ust.hk   \n",
       "1    2.0           Runze Cai                runze.cai@u.nus.edu   \n",
       "2    3.0            Xi Zheng           zheng.xi@my.cityu.edu.hk   \n",
       "3    4.0   Hanfang Lyu ¬¶ ÂêïÊ∂µÊîæ         hanfang.lyu@connect.ust.hk   \n",
       "4    5.0  Runhua ZHANG ¬¶ Âº†Ê∂¶Ëä±        runhua.zhang@connect.ust.hk   \n",
       "5    6.0   Xiang (Nathan) Qi    nathanxiang.qi@connect.polyu.hk   \n",
       "6    7.0           Fan Zhang                 zfan1218@gmail.com   \n",
       "7    8.0           Yuhao Sun                 yuhao.sun@ed.ac.uk   \n",
       "8    9.0       Yuanhao ZHANG            yzhangiy@connect.ust.hk   \n",
       "9   10.0           Yanna Lin                    cseyanna@ust.hk   \n",
       "10  11.0        LIU Dingdong              dliuak@connect.ust.hk   \n",
       "11  12.0       Liangwei Wang   lwang344@connect.hkust-gz.edu.cn   \n",
       "12  13.0           Yue Zhang                       yuezh@ust.hk   \n",
       "13  14.0           Zijun Mai        zijunmai@stu2023.jnu.edu.cn   \n",
       "14  15.0        Haoxiang Fan           fanhx6@mail2.sysu.edu.cn   \n",
       "15  16.0          Tianze XIE               tiaraaaxie@gmail.com   \n",
       "16  17.0             Han SHI              hshi22@m.fudan.edu.cn   \n",
       "17  18.0       Huanchen Wang     wanghc2022@mail.sustech.edu.cn   \n",
       "18  19.0             yao shi    yshi236@connect.hkust-gz.edu.cn   \n",
       "19  20.0             Sze Yiu             szeyiuchau@cuhk.edu.hk   \n",
       "20  21.0  Yuhan Zeng (Tsang)          yhzeng3-c@my.cityu.edu.hk   \n",
       "21  22.0             Wei Liu                liuwei.dk@gmail.com   \n",
       "22  23.0            Jiaan LI          jiaan.li@connect.polyu.hk   \n",
       "23  24.0       Chutian Jiang  cjiang893@connect.hkust-gz.edu.cn   \n",
       "24  25.0          Shixu ZHOU             szhouav@connect.ust.hk   \n",
       "25  26.0                 ÈÉ≠ËΩ∂Êç∑              guoyijie.sh@gmail.com   \n",
       "26  27.0                 Âº†Â≠êÊôó                  2237948243@qq.com   \n",
       "27  28.0            Ziqi Pan              zpanar@connect.ust.hk   \n",
       "28  29.0           Xuyu Yang        xuyuyang2-c@my.cityu.edu.hk   \n",
       "29  30.0         Yingna Wang   ywang885@connect.hkust-gz.edu.cn   \n",
       "30  31.0            Xin Tang              xintang0119@gmail.com   \n",
       "31  32.0          Zhihao Yao                yaozh_h@outlook.com   \n",
       "32  33.0              RAY LC                  recfreq@gmail.com   \n",
       "33  34.0  Maggie Yongqi Guan            maggiegyq2021@gmail.com   \n",
       "34  35.0           Tian Yang                   ytian@gxu.edu.cn   \n",
       "35  36.0                 ‰æØ‰ºäÊ∂µ    yhou073@connect.hkust-gz.edu.cn   \n",
       "36  37.0         Yuan Kangyu             kyuanaf@connect.ust.hk   \n",
       "37   1.0                 ÈÉ≠ËØóËæâ               guoshihui@xmu.edu.cn   \n",
       "38   2.0                 Á±≥Êµ∑Èπè                mhp@tsinghua.edu.cn   \n",
       "39   3.0                 Â≠ôÈì≠‰ºö                     smh@jlu.edu.cn   \n",
       "40   4.0                 È©¨Êò±Ê¨£                mayx@sustech.edu.cn   \n",
       "41   5.0                 ‰ªòÂøóÂãá          fuzhiyong@tsinghua.edu.cn   \n",
       "42   NaN             Wei Liu                liuwei.dk@gmail.com   \n",
       "\n",
       "                                          Affiliation  \\\n",
       "0                                 Shenzhen University   \n",
       "1                    National University of Singapore   \n",
       "2                        City University of Hong Kong   \n",
       "3   The Hong Kong University of Science and Techno...   \n",
       "4   The Hong Kong University of Science and Techno...   \n",
       "5                The Hong Kong Polytechnic University   \n",
       "6                        City University Of Hong Kong   \n",
       "7                             University of Edinburgh   \n",
       "8                                               HKUST   \n",
       "9                                               HKUST   \n",
       "10                                              HKUST   \n",
       "11  The Hong Kong University of Science and Techno...   \n",
       "12                                              HKUST   \n",
       "13                                   Jinan University   \n",
       "14                             Sun Yat-sen University   \n",
       "15                                            SUSTech   \n",
       "16                           SUSTech/Fudan University   \n",
       "17                                  SUSTech & CityUHK   \n",
       "18  The Hong Kong University of Science and Techno...   \n",
       "19                The Chinese University of Hong Kong   \n",
       "20                       City University of Hong Kong   \n",
       "21  School of Design, Southern University of Scien...   \n",
       "22                   Hong Kong Polytechnic University   \n",
       "23  Hong Kong University of Science and Technology...   \n",
       "24                                              HKUST   \n",
       "25                                Tsinghua University   \n",
       "26                                            SUSTech   \n",
       "27                                              HKUST   \n",
       "28                       City University of Hong Kong   \n",
       "29  The Hong Kong University of Science and Techno...   \n",
       "30                     Guangzhou Academy of Fine Arts   \n",
       "31                                Tsinghua University   \n",
       "32                       City University of Hong Kong   \n",
       "33                                University of Macau   \n",
       "34                                 Guangxi University   \n",
       "35  The Hong Kong University of Science and Techno...   \n",
       "36  The Hong Kong University of Science and Techno...   \n",
       "37           School of Informatics, Xiamen University   \n",
       "38      Academy of Arts & Design, Tsinghua University   \n",
       "39  School of Computer Science and Technology, Jil...   \n",
       "40  Dept. of Computer Science and Engineering, SUS...   \n",
       "41      Academy of Arts & Design, Tsinghua University   \n",
       "42  School of Design, Southern University of Scien...   \n",
       "\n",
       "                                                Title  \\\n",
       "0          [CHI25] Creative Blends of Visual Concepts   \n",
       "1   [CHI25] AiGet: Transforming Everyday Moments i...   \n",
       "2   [CHI25] Customizing Emotional Support: How Do ...   \n",
       "3   [CHI25] Signaling Human Intentions to Service ...   \n",
       "4   [CHI 25] Walk in Their Shoes to Navigate Your ...   \n",
       "5   [CHI25] Participatory Design in Human-Computer...   \n",
       "6   [CHI25] \"Becoming My Own Audience\": How Dancer...   \n",
       "7   [CHI25] Human-Precision Medicine Interaction: ...   \n",
       "8   [CHI25] CoKnowledge: Supporting Assimilation o...   \n",
       "9   [CHI25] InterLink: Linking Text with Code and ...   \n",
       "10  [CHI25] Scaffolded Turns and Logical Conversat...   \n",
       "11  VIzTA: Enhancing Comprehension of Distribution...   \n",
       "12  [CHI25] InsightBridge: Enhancing Empathizing w...   \n",
       "13  [CHI25] Modeling Locomotion with Body Angular ...   \n",
       "14  [CHI25] LitLinker: Supporting the Ideation of ...   \n",
       "15  [CHI25] VRCaptions: Design Captions for DHH Us...   \n",
       "16  [CHI25] ReachPad: Interacting with Multiple Vi...   \n",
       "17  [CHI25] HarmonyCut: Supporting Creative Chines...   \n",
       "18  [CHI25] Augmenting Realistic Charts with Virtu...   \n",
       "19  [CHI25] SeQR: A User-Friendly and Secure-by-De...   \n",
       "20  [CHI25] \"Ronaldo's a poser!\": How the Use of G...   \n",
       "21           [REP] Empathy-Driven Interaction Design    \n",
       "22  [CHI25] Designing and Evaluating a Narrative-d...   \n",
       "23  [CHI25] Designing LLM-Powered Multimodal Instr...   \n",
       "24  [CHI25] JournalAIde: Empowering Older Adults i...   \n",
       "25  [CHI25] Exploring the Design of LLM-based Agen...   \n",
       "26  [CHI25] Breaking Barriers or Building Dependen...   \n",
       "27  [CHI25] ACKnowledge: A Computational Framework...   \n",
       "28  [CHI25] Rambler in the Wild: A Diary Study of ...   \n",
       "29  [CHI25] Facilitating Daily Practice in Intangi...   \n",
       "30  Computational Methods for Batik Discovery, Pre...   \n",
       "31  Research on Digital Creative Tools for Traditi...   \n",
       "32  [CSCW] A Constructed Response: Designing and C...   \n",
       "33  [CHI25] Using Affordance to Understand Usabili...   \n",
       "34    [REP] Designing Highly Accessible XR Interfaces   \n",
       "35  [CHI25] GenColor: Generative Color-Concept Ass...   \n",
       "36  [CSCW] Exploring the Evolvement of User Engage...   \n",
       "37  Human Motion Capture for Everyone, Anywhere an...   \n",
       "38  Culture Inheritance and Design Innovation: Res...   \n",
       "39  GazePuffer : Hands-Free Input Method Leveragin...   \n",
       "40  Making Invisible Dynamics Visible: Case Studie...   \n",
       "41  Design Futures in HCI: Design Thinking for Dig...   \n",
       "42                 Empathy-Driven Interaction Design    \n",
       "\n",
       "                                             Abstract  \n",
       "0   Visual blends combine elements from two distin...  \n",
       "1   Unlike the free exploration of childhood, the ...  \n",
       "2   Personalized support is essential to fulfill i...  \n",
       "3   As service robots become commonplace, it is es...  \n",
       "4   Procrastination, the voluntary delay of tasks ...  \n",
       "5   Participatory Design (PD) has become increasin...  \n",
       "6   The use of motion capture in live dance perfor...  \n",
       "7   Precision Medicine (PM) transforms the traditi...  \n",
       "8   Danmaku, a system of scene-aligned, time-synce...  \n",
       "9   Computational notebooks, widely used for ad-ho...  \n",
       "10  Hospital admission interviews are critical for...  \n",
       "11  Comprehending visualizations requires readers ...  \n",
       "12  User-centered design necessitates researchers ...  \n",
       "13  This study proposes a time prediction model fo...  \n",
       "14  Teaching literature under interdisciplinary co...  \n",
       "15  Accessing auditory information remains challen...  \n",
       "16  The advancement of Virtual Reality (VR) has ex...  \n",
       "17  Chinese paper-cutting, an Intangible Cultural ...  \n",
       "18  In this paper, we introduce the concept of rea...  \n",
       "19  A classic problem in enterprise Wi-Fi is clien...  \n",
       "20  Online debates can enhance critical thinking b...  \n",
       "21  Empathy is a fundamental principle in Human-Co...  \n",
       "22  With the aging population, older adult patient...  \n",
       "23  Although remote learning is widely used for de...  \n",
       "24  Digital journaling offers a means for older ad...  \n",
       "25  Social difficulties have become an increasingl...  \n",
       "26  Breaking Barriers or Building Dependency? Expl...  \n",
       "27  Intelligent agents coexisting with humans ofte...  \n",
       "28  Speech-to-text technologies have been shown to...  \n",
       "29  The essence of intangible cultural heritage (I...  \n",
       "30  For centuries, Batik has served as a reflectio...  \n",
       "31  In the transformation process of re-mediating ...  \n",
       "32  In dance, dancers improvise and choreograph wi...  \n",
       "33  Web3 social media refers to a new generation o...  \n",
       "34                                                NaN  \n",
       "35  Existing approaches for color-concept associat...  \n",
       "36  The rise of AI-generated content (AIGC) is tra...  \n",
       "37                                                NaN  \n",
       "38                                                NaN  \n",
       "39                                                NaN  \n",
       "40                                                NaN  \n",
       "41                                                NaN  \n",
       "42  Empathy is a fundamental principle in Human-Co...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcbab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: ÂêàÂπ∂ Registrant Âíå Guest Êï∞ÊçÆÔºåÂª∫Á´ãÂÖ®Â±ÄÊò†Â∞Ñ\n",
    "registrant_guest = pd.concat([guest_df, sv_df, oc_df, registrant_df], ignore_index=True)\n",
    "email_to_name = registrant_guest.set_index(\"Email\")[\"Name\"].to_dict()\n",
    "email_to_org = registrant_guest.set_index(\"Email\")[\"Organization\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a1e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ÈÄöËøá Email ÂåπÈÖç Name Âíå Organization\n",
    "all_talks[\"speaker\"] = all_talks[\"Email\"].map(email_to_name)\n",
    "all_talks[\"affiliation\"] = all_talks[\"Email\"].map(email_to_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d60d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_speakers(title):\n",
    "    \"\"\"Âü∫‰∫éÊ†áÈ¢òÂåπÈÖçÊºîËÆ≤ËÄÖ‰ø°ÊÅØ\"\"\"\n",
    "    # ‰ºòÂÖàÂú®registrant_df‰∏≠Êü•Êâæ\n",
    "    all_talks_match = all_talks[all_talks[\"Title\"].str.contains(title, na=False, regex=False)].fillna(\"TBD\")\n",
    "    if not all_talks_match.empty:\n",
    "        return pd.Series({\n",
    "            \"speaker\": all_talks_match.iloc[0][\"speaker\"],  \n",
    "            \"affiliation\": all_talks_match.iloc[0][\"affiliation\"],\n",
    "            \"abstract\": all_talks_match.iloc[0][\"Abstract\"],\n",
    "        })\n",
    "    \n",
    "    # Êú™ÊâæÂà∞ÁöÑcase\n",
    "    return pd.Series({\n",
    "        \"speaker\": None,\n",
    "        \"affiliation\": None,\n",
    "        \"abstract\": None,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59bfe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: ÊâæÂà∞ÂØπÂ∫îÁöÑspeaker‰ø°ÊÅØ**\n",
    "program_df[[\"speaker\", \"affiliation\", \"abstract\"]] = program_df[\"title\"].apply(process_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bada9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "conference",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "speaker",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "affiliation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "af0f4b0e-447e-4577-a6c5-294244c9f9c4",
       "rows": [],
       "shape": {
        "columns": 6,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>title</th>\n",
       "      <th>conference</th>\n",
       "      <th>speaker</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [session, title, conference, speaker, affiliation, abstract]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_df[program_df[\"affiliation\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1b68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               session  \\\n",
      "0    A1 - GenAI-Enhanced Communication   \n",
      "1    A1 - GenAI-Enhanced Communication   \n",
      "2    A1 - GenAI-Enhanced Communication   \n",
      "3    A1 - GenAI-Enhanced Communication   \n",
      "4    A1 - GenAI-Enhanced Communication   \n",
      "5    A1 - GenAI-Enhanced Communication   \n",
      "6    A1 - GenAI-Enhanced Communication   \n",
      "7    A1 - GenAI-Enhanced Communication   \n",
      "8  B1 - Healthcare and Human Wellbeing   \n",
      "9  B1 - Healthcare and Human Wellbeing   \n",
      "\n",
      "                                               title  conference  \\\n",
      "0  Rambler in the Wild: A Diary Study of LLM-Assi...       CHI25   \n",
      "1  Scaffolded Turns and Logical Conversations: De...       CHI25   \n",
      "2  \"Ronaldo's a poser!\": How the Use of Generativ...       CHI25   \n",
      "3  JournalAIde: Empowering Older Adults in Digita...       CHI25   \n",
      "4  HarmonyCut: Supporting Creative Chinese Paper-...       CHI25   \n",
      "5  ACKnowledge: A Computational Framework for Hum...       CHI25   \n",
      "6  Exploring the Design of LLM-based Agent in Enh...       CHI25   \n",
      "7  Exploring the Evolvement of User Engagement in...        CSCW   \n",
      "8                  Empathy-Driven Interaction Design  Guest Talk   \n",
      "9  A Constructed Response: Designing and Choreogr...        CSCW   \n",
      "\n",
      "         speaker                                        affiliation  \\\n",
      "0      Xuyu YANG                       City University of Hong Kong   \n",
      "1   Dingdong LIU  The Hong Kong University of Science and Techno...   \n",
      "2     Yuhan Zeng                       City University of Hong Kong   \n",
      "3     Shixu ZHOU  The Hong Kong University of Science and Techno...   \n",
      "4  Huanchen WANG      Southern University of Science and Technology   \n",
      "5       Ziqi PAN  The Hong Kong University of Science and Techno...   \n",
      "6      Yijie GUO                                Tsinghua Univeristy   \n",
      "7    Kangyu YUAN  The Hong Kong University of Science and Techno...   \n",
      "8        Wei Liu      Southern University of Science and Technology   \n",
      "9         RAY LC                       City University of Hong Kong   \n",
      "\n",
      "                                            abstract  \n",
      "0  Speech-to-text technologies have been shown to...  \n",
      "1  Hospital admission interviews are critical for...  \n",
      "2  Online debates can enhance critical thinking b...  \n",
      "3  Digital journaling offers a means for older ad...  \n",
      "4  Chinese paper-cutting, an Intangible Cultural ...  \n",
      "5  Intelligent agents coexisting with humans ofte...  \n",
      "6  Social difficulties have become an increasingl...  \n",
      "7  The rise of AI-generated content (AIGC) is tra...  \n",
      "8  Empathy is a fundamental principle in Human-Co...  \n",
      "9  In dance, dancers improvise and choreograph wi...  \n"
     ]
    }
   ],
   "source": [
    "print(program_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e735ede",
   "metadata": {},
   "source": [
    "ÈªÑÊ≥ΩÂÆá [LT-17 Session 1]\n",
    "ÁéãÊ¢ÅÁÇú [LT-18 Session 1] \n",
    "\n",
    "Xi Zheng [LT-17 Session 2]\n",
    "Hanfang Lyu [LT-18 Session 2]\n",
    "\n",
    "ÈôàËÇ≤ÂÆâ [LT-17 Session 3]\n",
    "ËÆ∏ÊÑø [LT-18 Session 3]\n",
    "\n",
    "ÂæêÊáø [LT-15 Panel 1]\n",
    "ÈªÑÂ∫ÑÊ°ê[LT-15 Panel 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49423bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1 - GenAI-Enhanced Communication': 'Zeyu Huang',\n",
       " 'B1 - Healthcare and Human Wellbeing': 'Liangwei Wang',\n",
       " 'A2 - Interactive Systems and Data Visualization': 'Xi Zheng',\n",
       " 'B2 - New Media and Research Inspirations': 'Hanfang Lyu',\n",
       " 'A3 - Technology-Enhanced Learning and Heritage': \"Yu'an Chen\",\n",
       " 'B3 - Interaction in VR/AR': 'Yuan Xu'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_host_dict = dict(\n",
    "zip(program.keys(), [\"Zeyu Huang\", \"Liangwei Wang\", \"Xi Zheng\", \"Hanfang Lyu\", \"Yu'an Chen\", \"Yuan Xu\"])\n",
    ")\n",
    "session_host_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd7fb0",
   "metadata": {},
   "source": [
    "# Generate YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b25de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "\n",
    "def generate_id(title, conference):\n",
    "    \"\"\"Ê†πÊçÆÊ†áÈ¢òÂíå‰ºöËÆÆÁ±ªÂûãÁîüÊàêÂ∏¶ÂêéÁºÄÁöÑID\"\"\"\n",
    "    # Âü∫Á°ÄÂ§ÑÁêÜ\n",
    "    id_str = title.lower()\n",
    "    id_str = re.sub(r'[^\\w\\s-]', '', id_str)\n",
    "    id_str = re.sub(r'[\\s_]+', '-', id_str)\n",
    "    id_str = re.sub(r'-+', '-', id_str).strip('-')\n",
    "    \n",
    "    # Ê∑ªÂä†‰ºöËÆÆÁ±ªÂûãÂêéÁºÄ\n",
    "    conference_suffix = \"\"\n",
    "    if conference.lower() == \"guest talk\":\n",
    "        conference_suffix = \"-guest-talk\"\n",
    "    elif conference.lower() == \"rep\":\n",
    "        conference_suffix = \"-rep\"\n",
    "    \n",
    "    return f\"#{id_str}{conference_suffix}\"\n",
    "\n",
    "def generate_session_metadata(session_name_full):\n",
    "    \"\"\"Ê†πÊçÆSessionÂêçÁß∞ÁîüÊàêname„ÄÅlocationÂíålink\"\"\"\n",
    "    # ÊèêÂèñSessionÁºñÂè∑ÔºàÂ¶Ç\"A1\"Êàñ\"B1\"Ôºâ\n",
    "    session_name = session_name_full.split(\" - \")[-1].strip()  # ÊèêÂèñ \"GenAI-Enhanced Communication\"\n",
    "    session_code = session_name_full.split(\" - \")[0].strip()\n",
    "    # ÂàÜÈÖçÂú∞ÁÇπ\n",
    "    location = \"Yeung LT-17\" if session_code.startswith(\"A\") else \"Yeung LT-18\"\n",
    "    return {\n",
    "        \"name\": f\"Session {session_code}\",\n",
    "        \"location\": location,\n",
    "        \"topic\": session_name,\n",
    "        \"host\": session_host_dict.get(session_name_full, \"TBD\"),  # ‰ªésession_host_dict‰∏≠Ëé∑Âèñ‰∏ªÊåÅ‰∫∫\n",
    "        \"link\": f\"program/session_{session_code.lower()}\"\n",
    "    }\n",
    "    \n",
    "def format_speaker_name(name):\n",
    "    \"\"\"Áªü‰∏ÄÂßìÂêçÊ†ºÂºèÔºöÊØè‰∏™ÈÉ®ÂàÜÈ¶ñÂ≠óÊØçÂ§ßÂÜôÔºåÂÖ∂‰ΩôÂ∞èÂÜô\"\"\"\n",
    "    return ' '.join([part.strip().capitalize() for part in name.split()])\n",
    "\n",
    "# ÁîüÊàêYAMLÁªìÊûÑ\n",
    "sessions = []\n",
    "for session_group in program_df.groupby(\"session\"):\n",
    "    session_data = generate_session_metadata(session_group[0])\n",
    "    session_data[\"talks\"] = []\n",
    "    for _, row in session_group[1].iterrows():\n",
    "        full_title = f\"[{row['conference']}] {row['title']}\"\n",
    "        session_data[\"talks\"].append({\n",
    "            \"id\": generate_id(row[\"title\"], row[\"conference\"]),\n",
    "            \"title\": full_title,\n",
    "            \"speaker\": format_speaker_name(row[\"speaker\"])\n",
    "        })\n",
    "    \n",
    "    sessions.append(session_data)\n",
    "\n",
    "# ÂØºÂá∫YAML\n",
    "with open(\"program.yml\", \"w\") as f:\n",
    "    yaml.dump(sessions, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166fb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Session A1',\n",
       "  'location': 'Yeung LT-17',\n",
       "  'topic': 'GenAI-Enhanced Communication',\n",
       "  'host': 'Zeyu Huang',\n",
       "  'link': 'program/session_a1',\n",
       "  'talks': [{'id': '#rambler-in-the-wild-a-diary-study-of-llm-assisted-writing-with-speech',\n",
       "    'title': '[CHI25] Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech',\n",
       "    'speaker': 'Xuyu Yang'},\n",
       "   {'id': '#scaffolded-turns-and-logical-conversations-designing-humanized-llm-powered-conversational-agents-for-hospital-admission-interviews',\n",
       "    'title': '[CHI25] Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews',\n",
       "    'speaker': 'Dingdong Liu'},\n",
       "   {'id': '#ronaldos-a-poser-how-the-use-of-generative-ai-shapes-debates-in-online-forums',\n",
       "    'title': '[CHI25] \"Ronaldo\\'s a poser!\": How the Use of Generative AI Shapes Debates in Online Forums',\n",
       "    'speaker': 'Yuhan Zeng'},\n",
       "   {'id': '#journalaide-empowering-older-adults-in-digital-journal-writing',\n",
       "    'title': '[CHI25] JournalAIde: Empowering Older Adults in Digital Journal Writing',\n",
       "    'speaker': 'Shixu Zhou'},\n",
       "   {'id': '#harmonycut-supporting-creative-chinese-paper-cutting-design-with-form-and-connotation-harmony',\n",
       "    'title': '[CHI25] HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony',\n",
       "    'speaker': 'Huanchen Wang'},\n",
       "   {'id': '#acknowledge-a-computational-framework-for-human-compatible-affordance-based-interaction-planning-in-real-world-contexts',\n",
       "    'title': '[CHI25] ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts',\n",
       "    'speaker': 'Ziqi Pan'},\n",
       "   {'id': '#exploring-the-design-of-llm-based-agent-in-enhancing-self-disclosure-among-the-older-adults',\n",
       "    'title': '[CHI25] Exploring the Design of LLM-based Agent in Enhancing Self-disclosure Among the Older Adults',\n",
       "    'speaker': 'Yijie Guo'},\n",
       "   {'id': '#exploring-the-evolvement-of-user-engagement-in-online-creative-community-under-the-surge-of-generative-ai-a-case-study-of-deviantart',\n",
       "    'title': '[CSCW] Exploring the Evolvement of User Engagement in Online Creative Community under the Surge of Generative AI: A Case Study of DeviantArt',\n",
       "    'speaker': 'Kangyu Yuan'}]},\n",
       " {'name': 'Session A2',\n",
       "  'location': 'Yeung LT-17',\n",
       "  'topic': 'Interactive Systems and Data Visualization',\n",
       "  'host': 'Xi Zheng',\n",
       "  'link': 'program/session_a2',\n",
       "  'talks': [{'id': '#making-invisible-dynamics-visible-case-studies-in-visualizing-computational-and-behavioral-processes-guest-talk',\n",
       "    'title': '[Guest Talk] Making Invisible Dynamics Visible: Case Studies in Visualizing Computational and Behavioral Processes',\n",
       "    'speaker': 'Yuxin Ma'},\n",
       "   {'id': '#vizta-enhancing-comprehension-of-distributional-visualization-with-visual-lexical-fused-conversational-interface',\n",
       "    'title': '[EuroVis] VIzTA: Enhancing Comprehension of Distributional Visualization with Visual-Lexical Fused Conversational Interface',\n",
       "    'speaker': 'Liangwei Wang'},\n",
       "   {'id': '#insightbridge-enhancing-empathizing-with-users-through-real-time-information-synthesis-and-visual-communication',\n",
       "    'title': '[CHI25] InsightBridge: Enhancing Empathizing with Users through Real-Time Information Synthesis and Visual Communication',\n",
       "    'speaker': 'Yue Zhang'},\n",
       "   {'id': '#interlink-linking-text-with-code-and-outputs-in-computational-notebooks',\n",
       "    'title': '[CHI25] InterLink: Linking Text with Code and Outputs in Computational Notebooks',\n",
       "    'speaker': 'Yanna Lin'},\n",
       "   {'id': '#creative-blends-of-visual-concepts',\n",
       "    'title': '[CHI25] Creative Blends of Visual Concepts',\n",
       "    'speaker': 'Zhida Sun'},\n",
       "   {'id': '#gencolor-generative-color-concept-association-in-visual-design',\n",
       "    'title': '[CHI25] GenColor: Generative Color-Concept Association in Visual Design',\n",
       "    'speaker': 'Yihan Hou'}]},\n",
       " {'name': 'Session A3',\n",
       "  'location': 'Yeung LT-17',\n",
       "  'topic': 'Technology-Enhanced Learning and Heritage',\n",
       "  'host': \"Yu'an Chen\",\n",
       "  'link': 'program/session_a3',\n",
       "  'talks': [{'id': '#culture-inheritance-and-design-innovation-research-practice-at-milab-guest-talk',\n",
       "    'title': '[Guest Talk] Culture Inheritance and Design Innovation: Research Practice at MILAB',\n",
       "    'speaker': 'Haipeng Mi'},\n",
       "   {'id': '#coknowledge-supporting-assimilation-of-time-synced-collective-knowledge-in-online-science-videos',\n",
       "    'title': '[CHI25] CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos',\n",
       "    'speaker': 'Yuanhao Zhang'},\n",
       "   {'id': '#designing-llm-powered-multimodal-instructions-to-support-rich-hands-on-skills-remote-learning-a-case-study-with-massage-instructors-and-learners',\n",
       "    'title': '[CHI25] Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners',\n",
       "    'speaker': 'Chutian Jiang'},\n",
       "   {'id': '#breaking-barriers-or-building-dependency-exploring-team-llm-collaboration-in-ai-infused-classroom-debate',\n",
       "    'title': '[CHI25] Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate',\n",
       "    'speaker': 'Zihan Zhang'},\n",
       "   {'id': '#litlinker-supporting-the-ideation-of-interdisciplinary-contexts-with-large-language-models-for-teaching-literature-in-elementary-schools',\n",
       "    'title': '[CHI25] LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools',\n",
       "    'speaker': 'Haoxiang Fan'}]},\n",
       " {'name': 'Session B1',\n",
       "  'location': 'Yeung LT-18',\n",
       "  'topic': 'Healthcare and Human Wellbeing',\n",
       "  'host': 'Liangwei Wang',\n",
       "  'link': 'program/session_b1',\n",
       "  'talks': [{'id': '#empathy-driven-interaction-design-guest-talk',\n",
       "    'title': '[Guest Talk] Empathy-Driven Interaction Design',\n",
       "    'speaker': 'Wei Liu'},\n",
       "   {'id': '#a-constructed-response-designing-and-choreographing-robot-arm-movements-in-collaborative-dance-improvisation',\n",
       "    'title': '[CSCW] A Constructed Response: Designing and Choreographing Robot Arm Movements in Collaborative Dance Improvisation',\n",
       "    'speaker': 'Ray Lc'},\n",
       "   {'id': '#human-precision-medicine-interaction-public-perceptions-of-polygenic-risk-score-for-genetic-health-prediction',\n",
       "    'title': '[CHI25] Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction',\n",
       "    'speaker': 'Yuhao Sun'},\n",
       "   {'id': '#designing-and-evaluating-a-narrative-driven-spatial-visualization-for-improving-patient-centered-communication-among-older-adults',\n",
       "    'title': '[CHI25] Designing and Evaluating a Narrative-driven Spatial Visualization for Improving Patient-centered Communication among Older Adults',\n",
       "    'speaker': 'Jiaan Li'},\n",
       "   {'id': '#walk-in-their-shoes-to-navigate-your-own-path-learning-about-procrastination-through-a-serious-game',\n",
       "    'title': '[CHI 25] Walk in Their Shoes to Navigate Your Own Path: Learning About Procrastination Through A Serious Game',\n",
       "    'speaker': 'Runhua Zhang'},\n",
       "   {'id': '#customizing-emotional-support-how-do-individuals-construct-and-interact-with-llm-powered-chatbots',\n",
       "    'title': '[CHI25] Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots',\n",
       "    'speaker': 'Xi Zheng'},\n",
       "   {'id': '#signaling-human-intentions-to-service-robots-understanding-the-use-of-social-cues-during-in-person-conversations',\n",
       "    'title': '[CHI25] Signaling Human Intentions to Service Robots: Understanding the Use of Social Cues during In-Person Conversations',\n",
       "    'speaker': 'Hanfang Lyu'},\n",
       "   {'id': '#becoming-my-own-audience-how-dancers-react-to-avatars-unlike-themselves-in-motion-capture-supported-live-improvisational-performance',\n",
       "    'title': '[CHI25] \"Becoming My Own Audience\": How Dancers React to Avatars Unlike Themselves in Motion Capture-Supported Live Improvisational Performance',\n",
       "    'speaker': 'Fan Zhang'}]},\n",
       " {'name': 'Session B2',\n",
       "  'location': 'Yeung LT-18',\n",
       "  'topic': 'New Media and Research Inspirations',\n",
       "  'host': 'Hanfang Lyu',\n",
       "  'link': 'program/session_b2',\n",
       "  'talks': [{'id': '#design-futures-in-hci-design-thinking-for-digital-transformation-guest-talk',\n",
       "    'title': '[Guest Talk] Design Futures in HCI: Design Thinking for Digital Transformation ',\n",
       "    'speaker': 'Zhiyong Fu'},\n",
       "   {'id': '#designing-highly-accessible-xr-interfaces-rep',\n",
       "    'title': '[REP] Designing Highly Accessible XR Interfaces',\n",
       "    'speaker': 'Yang Tian'},\n",
       "   {'id': '#participatory-design-in-human-computer-interaction-cases-characteristics-and-lessons',\n",
       "    'title': '[CHI25] Participatory Design in Human-Computer Interaction: Cases, Characteristics, and Lessons',\n",
       "    'speaker': 'Xiang (nathan) Qi'},\n",
       "   {'id': '#seqr-a-user-friendly-and-secure-by-design-configurator-for-enterprise-wi-fi',\n",
       "    'title': '[CHI25] SeQR: A User-Friendly and Secure-by-Design Configurator for Enterprise Wi-Fi',\n",
       "    'speaker': 'Sze Yiu Chau'},\n",
       "   {'id': '#using-affordance-to-understand-usability-of-web3-social-media',\n",
       "    'title': '[CHI25] Using Affordance to Understand Usability of Web3 Social Media',\n",
       "    'speaker': 'Maggie Yongqi Guan'}]},\n",
       " {'name': 'Session B3',\n",
       "  'location': 'Yeung LT-18',\n",
       "  'topic': 'Interaction in VR/AR',\n",
       "  'host': 'Yuan Xu',\n",
       "  'link': 'program/session_b3',\n",
       "  'talks': [{'id': '#gazepuffer-hands-free-input-method-leveraging-puff-cheeks-for-vr-guest-talk',\n",
       "    'title': '[Guest Talk] GazePuffer : Hands-Free Input Method Leveraging Puff Cheeks for VR',\n",
       "    'speaker': 'Minghui Sun'},\n",
       "   {'id': '#aiget-transforming-everyday-moments-into-hidden-knowledge-discovery-with-ai-assistance-on-smart-glasses',\n",
       "    'title': '[CHI25] AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses',\n",
       "    'speaker': 'Runze Cai'},\n",
       "   {'id': '#augmenting-realistic-charts-with-virtual-overlays',\n",
       "    'title': '[CHI25] Augmenting Realistic Charts with Virtual Overlays',\n",
       "    'speaker': 'Yao Shi'},\n",
       "   {'id': '#modeling-locomotion-with-body-angular-movements-in-virtual-reality',\n",
       "    'title': '[CHI25] Modeling Locomotion with Body Angular Movements in Virtual Reality',\n",
       "    'speaker': 'Zijun Mai'},\n",
       "   {'id': '#vrcaptions-design-captions-for-dhh-users-in-multiplayer-communication-in-vr',\n",
       "    'title': '[CHI25] VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR',\n",
       "    'speaker': 'Tianze Xie'},\n",
       "   {'id': '#reachpad-interacting-with-multiple-virtual-screens-using-a-single-physical-pad-through-haptic-retargeting',\n",
       "    'title': '[CHI25] ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting',\n",
       "    'speaker': 'Han Shi'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686f912",
   "metadata": {},
   "source": [
    "# Generate Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c990447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï\n",
    "output_dir = Path(\"sessions\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def format_talk_title(title, conference):\n",
    "    \"\"\"Â§ÑÁêÜÊ†áÈ¢òÊ†ºÂºèÔºöÁßªÈô§ÂéüÂßã‰ºöËÆÆÊ†áËÆ∞ÔºåÂπ∂Ê†πÊçÆÁ±ªÂûãÊ∑ªÂä†ÂêéÁºÄ\"\"\"\n",
    "    # ÁßªÈô§ÂéüÂßã‰ºöËÆÆÊ†áËÆ∞ÔºàÂ¶Ç [CHI25]Ôºâ\n",
    "    clean_title = re.sub(r'^$$.*?$$\\s*', '', title)\n",
    "    \n",
    "    # Ê†πÊçÆ‰ºöËÆÆÁ±ªÂûãÊ∑ªÂä†ÂêéÁºÄ\n",
    "    if conference == \"Guest Talk\":\n",
    "        return f\"{clean_title} [Guest Talk]\"\n",
    "    elif conference == \"REP\":\n",
    "        return f\"{clean_title} [REP]\"\n",
    "    else:\n",
    "        return clean_title\n",
    "\n",
    "def generate_md(session_data):\n",
    "    \"\"\"ÁîüÊàêÂçï‰∏™sessionÁöÑMarkdownÂÜÖÂÆπ\"\"\"\n",
    "    content = f\"## {session_data['topic']}\\n\\n\"\n",
    "    content += f\"‚Äã**‚ÄãSession Host**‚Äã: {session_data.get('host', 'TBD')}\\n\\n\"\n",
    "    \n",
    "    for talk in session_data['talks']:\n",
    "        # Ê†áÈ¢òÈÉ®ÂàÜ\n",
    "        title_line = f\"### {format_talk_title(talk['title'], talk['conference'])}\"\n",
    "        content += f\"{title_line}\\n\\n\"\n",
    "        \n",
    "        # ÊºîËÆ≤ËÄÖ‰ø°ÊÅØ\n",
    "        content += f\"‚Äã**‚ÄãSpeaker‚Äã**‚Äã: {talk['speaker']}\"\n",
    "        if talk.get('affiliation'):\n",
    "            content += f\", *{talk['affiliation']}*\"\n",
    "        content += \"\\n\\n\"\n",
    "        \n",
    "        # ÊëòË¶ÅÈÉ®ÂàÜ\n",
    "        content += f\"‚Äã**‚ÄãAbstract‚Äã**‚Äã:\\n {talk['abstract']}\\n\\n\\n\"  # ÁïôÁ©∫ÊàñÊ∑ªÂä†Âç†‰ΩçÁ¨¶\n",
    "        \n",
    "    return content\n",
    "\n",
    "\n",
    "sessions = []\n",
    "for session_group in program_df.groupby(\"session\"):\n",
    "    session_data = generate_session_metadata(session_group[0])\n",
    "    session_data[\"talks\"] = []\n",
    "    for _, row in session_group[1].iterrows():\n",
    "        session_data[\"talks\"].append({\n",
    "            \"title\": row['title'],\n",
    "            \"conference\": row['conference'],\n",
    "            \"speaker\": format_speaker_name(row[\"speaker\"]),\n",
    "            \"affiliation\": row[\"affiliation\"],\n",
    "            \"abstract\": row['abstract'] if row['abstract'] != \"nan\" else \"TBD\",\n",
    "        })\n",
    "    \n",
    "    sessions.append(session_data)\n",
    "    \n",
    "\n",
    "# ÈÅçÂéÜÊØè‰∏™sessionÁîüÊàêÊñá‰ª∂\n",
    "for session in sessions:\n",
    "    # ÁîüÊàêÂÆâÂÖ®Êñá‰ª∂Âêç\n",
    "    filename = re.sub(r'[^\\w\\s-]', '', session['name']).strip().lower()\n",
    "    filename = re.sub(r'[-\\s]+', '-', filename) + \".md\"\n",
    "    \n",
    "    # ÂÜôÂÖ•Êñá‰ª∂\n",
    "    with open(output_dir / filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(generate_md(session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedae174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
